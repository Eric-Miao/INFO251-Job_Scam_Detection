{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a5a5e36",
   "metadata": {},
   "source": [
    "# Log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc28b031-13d2-4e08-9d55-e4a0783006db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, r2_score ,confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier ,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier ,ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cf425f8-20ec-4854-92f8-564fc20c744f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food52 created groundbreaking award winning co...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90 seconds worlds cloud video production servi...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valor services provides workforce solutions me...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passion improving quality life geography heart...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotsource solutions llc global human capital ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>vend looking awesome new talent come join us w...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>weblinc e commerce platform services provider ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>provide full time permanent positions many med...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>nemsia studios looking experienced visual grap...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>vend looking awesome new talent come join us w...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text fraudulent\n",
       "0      food52 created groundbreaking award winning co...          f\n",
       "1      90 seconds worlds cloud video production servi...          f\n",
       "2      valor services provides workforce solutions me...          f\n",
       "3      passion improving quality life geography heart...          f\n",
       "4      spotsource solutions llc global human capital ...          f\n",
       "...                                                  ...        ...\n",
       "17875  vend looking awesome new talent come join us w...          f\n",
       "17876  weblinc e commerce platform services provider ...          f\n",
       "17877  provide full time permanent positions many med...          f\n",
       "17878  nemsia studios looking experienced visual grap...          f\n",
       "17879  vend looking awesome new talent come join us w...          f\n",
       "\n",
       "[17880 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../../Data/text.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f987ceb8-4409-4f95-aed9-541259c71eed",
   "metadata": {},
   "source": [
    "# Bag of Words using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb986a83-34da-4a9f-84fc-2a79a49f92aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17014\n",
       "1      866\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fraudulent']=df['fraudulent'].replace('f', 0)\n",
    "df['fraudulent']=df['fraudulent'].replace('t', 1)\n",
    "df['fraudulent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c74fea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             fraudulent\n",
       "accepting online applications click apply full time temporary position lasting 2 years description validate review legal contractual agreements customers input contract contract databases contracts completed amp reviewed within per determined service level agreement professional e mail interaction customers scanning uploading documents qualifications high school diploma equivalent professional communication skills via e mail interaction dedicated needs business project management skills assist facilitating multiple contract rejects detail oriented able multi task ability work time sensitive documents must able work independently able perform team environment needed fast accurate typist accepting online applications click apply data entry admin clerical positions work home us ne omaha                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1             4\n",
       "aker solutions global provider products systems services oil gas industry engineering design technology bring discoveries production maximize recovery petroleum field employ approximately 28 000 people 30 countries go information business people values corporate overview aker solutions global provider products systems services oil gas industry engineering design technology bring discoveries production maximize recovery petroleum field employ approximately 28 000 people 30 countries go information business people values successor current manager looking head machining department responsibilities tasks professional disciplinary management machining department production processes drilling milling turning primarily cnc machines used machine large heavy metal work pieces also teams tooling cnc programming belongs department whole department consists present 3 foreperson areas around 60 employees meeting deadlines pertinent production department using appropriate sap tools milestone planning continuous optimization production processes cip 6s planning respect preventative maintenance measures plant modernization new acquisitions preparation corresponding information serving bases decision making including cost benefit analyses assistance roi calculations determination wages salaries consultation production manager forepersons specialized department human resource planning human resource development succession planning cost deadline quality assurance work part cross departmental team acting contact person design sales departments along production departments regards technical organisational matters supporting supply chain management quality management departments concerning selection assignment suitable suppliers well continuous assessment suppliers performance production consulting handling health safety environment issues within department compliance relevant regulations directives ensured steps towards continuous optimization taken qualifications amp personal attributes good higher education degree area production technology least three years experience management also consider second tier candidates team leaders deputies necessary experience qualifications comprehensive knowledge machining production techniques machining processes essential previous training area machining would beneficial creativity analytical thinking talent organisation confident demeanour ability work team mark good academic background notwithstanding speak language production department therefore adequately cope technical personnel related challenges understand incorporate know employees decision making convince employees effectiveness proposed improvements motivate accordingly good command english language sound ability use modern data processing tools round profile willingness travel occasionally lt 10 time required offer friendly colleagues industry bright future environment encouraged develop skills share knowledge colleagues competitive benefits strong focus work life balance exciting work environment versatile challenges maximum creative leeway flat hierarchies scope initiative us tx houston full time bachelor degree oil energy engineering                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1             2\n",
       "6 ultra luxury american cruise company urgently looking following positions hospitality many bars amp restaurants board retail duty free shops amp boutiques board housekeeping housekeeping amp cleaning jobs office admin front desk amp tour booking jobs positions dj security staff photographers amp nannies vessel type operation 6 ultra luxury cruise certification amp experience previous experience required good english speaker customer service skills wanting learn amp work job type perm sailing area world wide benefits board en suite accommodation food medical cover duration contract world work visa free wifi tax free salary amp job description 6 ultra luxury cruise company looking recruit hardworking enthusiastic cruise personal exciting opportunity available candidates willing learn work amp flexible candidate also customer service skills skills public relations good english speakers rotation 4 months 2 months great salary euros tax free pay discussed via communication full application proccess looking new adventure apply today please send resume coppy amp paste e mail address contact shortly within 24 hours looking forward aboard adrian westdept rec certification amp experience previous experience required good english speaker customer service skills wanting learn amp work benefits board en suite accommodation food medical cover duration contract world work visa free wifi tax free salary amp cruise staff wanted urgent us ny manhattan full time leisure travel tourism                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1             2\n",
       "looking contractors individual perform general maintenance repairs residential properties work may include limited following grass cuts general repairs perform per bid approvals trash outs debris removal eviction services initial secures securing replacing locks winterizations boarding mold remediation cash keys janitorial cleaning home interior note must necessary tools perform tasks subject pass background check know perform winterization property plus must digital camera take photographs supporting work done also require use email work time sensitive strong work ethic preferred note please sure include full name city located phone number email order considered position name phone email response response deleted thanks look forward hearing per job property preservation field crews us md rockville contract real estate                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1             2\n",
       "6 ultra luxury american cruise company urgently looking following positions hospitality many bars amp restaurants board retail duty free shops amp boutiques board housekeeping housekeeping amp cleaning jobs office admin front desk amp tour booking jobs positions dj security staff photographers amp nannies vessel type operation 6 ultra luxury cruise certification amp experience previous experience required good english speaker customer service skills wanting learn amp work job type perm sailing area world wide benefits board en suite accommodation food medical cover duration contract world work visa free wifi tax free salary amp job description 6 ultra luxury cruise company looking recruit hardworking enthusiastic cruise personal exciting opportunity available candidates willing learn work amp flexible candidate also customer service skills skills public relations good english speakers rotation 4 months 2 months great salary euros tax free pay discussed via communication full application proccess looking new adventure apply today please send resume coppy amp paste e mail address contact shortly within 24 hours looking forward aboard adrian westdept rec certification amp experience previous experience required good english speaker customer service skills wanting learn amp work benefits board en suite accommodation food medical cover duration contract world work visa free wifi tax free salary amp cruise staff wanted urgent us tx dallas leisure travel tourism                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1             2\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ..\n",
       "eroad established modernise new zealand paper based ruc regime 2009 launched world first gps cellular based road charging system solution readily rapidly scaled deployed across entire jurisdictions bebecause requires roadside architecture uses saas based web service world leader field expanding rapidly enter new markets joining eroad great career move look potential hiring ability grow role employ best ensure staff skills training technology best work fit eroad important well really proud company culture finding people right attitude essential great cv working eroad means learning people experts field also means working hard able grow fast need encourage healthy work life balance low staff turnover tells us probably got balance right staff globe 25 countries last count may highest rate boat surfboard windsurfer ownership technology company anywhere lookout passionate experienced test engineer join firmware team firmware test position open range experience working new innovative products fast paced hi tech organisation working one nz fastest growing technology companies playing essential part ensuring web mobile applications tested highest standard positon sits within firmware team involved testing new products excellent opportunity tester either background software firmware excel important aspect role motivation drive continuous improvement want someone enjoys working part team creating test methodology improve product ideally experience working agile environment would advantageous hold testing certification accreditation e istqb excellent opportunity utilise test knowledge also challenge problem solving ability business products grow test engineer involved following tasks analyse provide input technical requirement specifications create execute test plans test scripts test cases well peer reviewing others within test team think outside box inventive designing building upon existing automated test framework smoke regression testing contribute creating test best practice help drive continuous improvement around test tools procedures provide weekly status reporting using test management tools outline feature delivery developers testing progress interested speaking people hold following attributes experience least 4 years testing experience preferably exposure manual automated testing sound understanding various test methodologies current best practices proven experience various test types functional system usability integration regression broad experience defect management test management tools basic sql experience excellent interpersonal communication skills ability work members development business teams sound analytical problem solving skills ideally hold experience technical requirement specification analysis strong time management proven ability meeting deadlines highly motivated capability manage large pieces project without direct management would advantageous experience following experience selenium badboy experience soapui jmeter etc basic unix virtualisation vmware aws passion technology eye detail please apply today nz full time associate bachelor degree computer software information technology                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0             1\n",
       "eroad established modernise new zealand paper based ruc regime 2009 launched world first gps cellular based road charging system solution readily rapidly scaled deployed across entire jurisdictions bebecause requires roadside architecture uses saas based web service world leader field expanding rapidly enter new markets joining eroad great career move look potential hiring ability grow role employ best ensure staff skills training technology best work fit eroad important well really proud company culture finding people right attitude essential great cv working eroad means learning people experts field also means working hard able grow fast need encourage healthy work life balance low staff turnover tells us probably got balance right staff globe 25 countries last count may highest rate boat surfboard windsurfer ownership technology company anywhere looking quality focused coordinator take responsibility goods receipt despatch transfer processes factory factory located premises head office albany auckland coordinate goods receipt despatch transfer processes role encompass freight co ordination monitoring accessories finished goods stock levels placing orders refurbishing stock levels based set reorder points absolute focus quality quickly develop expert knowledge supply chain module excellent track record inwards outwards freight inventory co ordination responsibilities monitor fg accessories stock levels receipt put away eroad incoming goods dispatch transfer customer intercompany order requirements dedication continuous improvement innovation excellent time management excellent written verbal communication exceptionally well organised methodical great communicator want part high performing team want hear eroad offers competitive salary benefits excellent career development opportunities fun fast paced work environment inwards outwards goods coordinator nz n auckland full time associate warehousing                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0             1\n",
       "erg business consumer law firm dedicated helping clients navigate bp claims process almost every type business west coast florida many individuals professionals may qualified particpate new bp funded program established june 4 2012 purpose program help florida businesses consumers recover direct indirect impacts 2010 deepwater horizon oil spill erg team lawyers financial professionals dedicated ensuring impacted receive quality representation deserve ability file claim time limited investigate rights today ensure intended benefits program realized florida economy continues struggle visit erg whether company may claim direct marketing consulting advising commission service non profit job tool need kit clients associates friends neighbors eleven month opportunity earn much little interested simply communicating friends business associates along coast florida brief outline local representative position economic recovery group llc florida law firm devoted spreading word potential claimants new bp horizon settlement program essentially everything need know faq covered one hour webinar training emailed variety updates looking businesses nonprofits independent contractors produce 60 months p amp l statements downturn 2010 2011 show upturn 63 ways make determination general claim follow pattern excluded classes bankers insurers bp station owners investment advisers casinos local governments probably common find somebody might interested refer regional representative encourage fill paperwork evaluate whether may file claim staff attorney winter park office contact assist putting together documentation filing claim one also looking groups present leads come meetings belong local representative presentations someone erg lines invite local representatives give claim forms interested become well 20 billion dollars worth claims walking around biggest settlement agreement ever filed april 22 2014 file claims barred rough estimate 800 000 potential claimants coastal florida production requirement opportunity take much little advantage want signed employee economic recovery group state bar florida requires employee furnish business cards marketing materials let know interested email call something might interest cell phone_2c9e2730fd93423ce8b7a871ebeeaef430843c21c17585b0181eda889db552b5 phone_75ae6759d433d010ff7bbb7f46a83587f6befc19df50986f4d1fbab112862582 best david _______________________ david k easlick jr jd mba community representative regional human resources representative economic recovery group llc 1936 lee road suite 105 winter park florida 32789 e w 888 270 6288 c 843 522 0679 local representative receive 1 claim amount client receives bp settlement nothing refer client us attorney client privilege attaches sign documents one staff attorney privy financial information compensation comes attorney fee way diminishes recovery client also happen recruit others interested local reps would also get 25 referral 1 commission us fl estero                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0             1\n",
       "envision consulting conducts retained searches nonprofit clients seeking expand enhance mission talent acquisitions specialize providing solutions profit organizations offering coaching planning staffing tailored specifically growth impact bebecause understand nonprofit arena envision consulting uniquely positioned attract engage passionate experienced learn envision consulting employer agency provides quality mental health social services populations consisting mentally ill homeless mentally ill multi diagnosed individuals substance abuse disorders agency community based services available regardless age ethnicity ability pay programs encompass full continuum prevention early intervention treatment services individuals families community clients actively participate determining treatment goals encouraged involved program planning evaluation agency supports work environment encourages individual team excellence caring clients responsibilities agency seeking associate executive director help build solid platform future sustainability success building vision ceo reporting ceo associate executive director provide day day leadership strategy management compliance organization outstanding opportunity proven leader operational experience track record creative problem solving join high growth mission driven organization core areas focus include following strategic planning vision leadership contribute development agency strategic goals objectives well overall management organization represent organization externally necessary direct implement appropriate legal compliance reporting auditing activities ensure integrity viability organization upgrade implement appropriate system policies internal controls compliance standards procedures organizational leadership manage day day operations agency including administrative development human resource planning functions oversee direct organize work programming operations teams promote culture high performance continuous improvement values learning commitment quality establish monitor staff performance development goals update job descriptions assign accountabilities set objectives establish priorities conduct annual performance appraisals administer salary adjustments maintain continuous lines communication keeping ceo informed critical issues conduct official correspondence behalf ceo board directors appropriate jointly appropriate mentor develop staff using supportive collaborative approach assign accountabilities set objectives establish priorities monitor evaluate results manage overall information technology clinitrack ensure development implementation maintenance hardware software meet changing needs agency funders accurate complete information including electronic health records create collaboration among staff various programs overseeing clinical programs best serve clients overall population contracts compliance supervise quality assurance department ensure compliance contracts primarily los angeles county department mental health represent agency bidding process audits act agency representative within contract negotiations compliance audits well within bidding process manage rfp process manage collaborate internal contracted staff respond relevant rfps grants applicable funding applications requests oversee contracts administration function ensure program activities reporting comply contracts accreditation standards licensing requirements regulations agency policies procedures experience minimum 5 years demonstrated operations success government contractors including dmh dcfs dpss housing agencies clinical licensure psychologist clinical social worker marriage family therapist preferred proven record managing multicultural interdisciplinary team experience spa 6 los angeles county dmh highly preferred prior experience executive director nonprofit organization budget greater 250 000 per year preferred education masters degree required salary benefits high profile leadership position based los angeles offers wonderful working environment among devoted staff board members opportunity professional organizational growth exceptional package health benefits vacation pto time competitive first year annual base salary job love us ca full time master degree nonprofit organization management administrative  0             1\n",
       "ÑƒÑƒÑ€Ñ€Ð°Ð° Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‰Ð°Ñ Ð² ÑÑ„ÐµÑ€Ðµ b2b Ð² Ñ€Ð¾ÑÑÐ¸Ð¸ Ð¼Ñ‹ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ñ‹ Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ ÑÐ½Ð¸Ð¼Ð°ÑŽÑ‰Ð¸Ðµ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð¸ Ð´ÐµÐ»Ð°ÑŽÑ‰Ð¸Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¾Ð¿Ñ‚Ð¾Ð²Ñ‹Ñ… Ð·Ð°ÐºÑƒÐ¿Ð¾Ðº Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð¶ Ð½Ð°ÑˆÐ° Ñ†ÐµÐ»ÑŒ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ñ‹ Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´ÐµÐ»Ð°ÑŽÑ‰Ð¸Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¾Ð¿Ñ‚Ð¾Ð²Ñ‹Ñ… Ð·Ð°ÐºÑƒÐ¿Ð¾Ðº Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð¶ Ð² ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐ³Ð¾ Ð¸ Ð¼Ð°Ð»Ð¾Ð³Ð¾ Ð±Ð¸Ð·Ð½ÐµÑÐ° Ð¼Ñ‹ ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… online Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð¸Ð· ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½ÑƒÑŽ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð»Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÑˆÐ°Ð³ ÑƒÐ´Ð¾Ð±Ð½Ð°Ñ Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÐºÐ° Ð¿Ñ€ÐµÐ´Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð¾Ð² Ð¸ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ñ€Ð¾ÑÑÐ¸Ð¸ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¸ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÑŒ Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹ Ð¼Ñ‹ ÑÑ‚Ñ€Ð¾Ð¸Ð¼ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑŽ Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð½Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ð½Ð¾Ð²Ð°Ñ‚Ð¾Ñ€ÑÑ‚Ð²Ðµ Ð¸ Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ð¸ Ð½Ð°Ð¼ Ð½ÑƒÐ¶Ð½Ñ‹ ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ…Ð¾Ñ‚ÑÑ‚ Ð¿Ð¾ÐºÐ¾Ñ€Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð³Ð¾Ñ€Ð¸Ð·Ð¾Ð½Ñ‚Ñ‹ Ð½Ðµ Ð±Ð¾ÑÑ‚ÑÑ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð±Ð¸Ð·Ð½ÐµÑ Ñ Ð½ÑƒÐ»Ñ Ð¸ Ñ‚Ð°Ðº ÐºÐ°Ðº Ð¾Ð½Ð¸ ÑÑ‡Ð¸Ñ‚Ð°ÑŽÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð½Ð°Ð¼ Ð½ÑƒÐ¶Ð½Ñ‹ ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸ Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾ Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð½Ð¾ Ð¸ Ð¾Ñ‚Ð´Ñ‹Ñ…Ð°Ñ‚ÑŒ plan development release new products features defining control points following plan execution specifying market requirements current future products conducting market research supported going visits customers non customers development product personas users interface prototype product requirements documentation perform acceptance testing product development iteration make go go decision conduct b test different product interfaces functionality analyze results implement winning results driving solution set across development teams primarily development engineering marketing communications market requirements product documentation positioning 3 years product management experience mobile preferred demonstrated success defining launching mobile apps products bachelor degree info systems computer science preferred technical background 2 years experience excellent verbal written communication skills including ability effectively communicate internal external customers proven ability influence cross functional teams without formal authority must able work pressure meet deadlines maintaining positive attitude providing exemplary customer service ability work independently carry assignments completion within parameters instructions given prescribed routines standard accepted practices excellent computer proficiency ui ux creating tools preferred mobile product manager full time internet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0             1\n",
       "Length: 1851, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df['fraudulent']==0]\n",
    "df1 = df1.sample(1000)\n",
    "print(len(df1))\n",
    "df2 = df[df['fraudulent']==1]\n",
    "\n",
    "print(len(df2))\n",
    "\n",
    "df_balanced = pd.concat([df1,df2],axis=0)\n",
    "\n",
    "df_balanced = df_balanced.sample(frac=1) #shuffle all rows\n",
    "df_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e7b649-1116-47ea-a859-cefd6197eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['text'], df_balanced['fraudulent'], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c2c3f3-693a-4307-8bc8-ce0e01fdbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(ngram_range=(1, 1), lowercase = True , stop_words =  'english')\n",
    "\n",
    "X_train = count_vector.fit_transform(X_train) \n",
    "X_test = count_vector.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e5c66c",
   "metadata": {},
   "source": [
    "# Traditional Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7660516",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "552148cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15626 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "X_train_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "38fdd9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression() _ Train Details</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression() _ Test Details</th>\n",
       "      <td>91.863</td>\n",
       "      <td>91.593</td>\n",
       "      <td>90.393</td>\n",
       "      <td>92.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier() _ Train Details</th>\n",
       "      <td>74.196</td>\n",
       "      <td>77.592</td>\n",
       "      <td>64.566</td>\n",
       "      <td>97.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier() _ Test Details</th>\n",
       "      <td>71.306</td>\n",
       "      <td>76.325</td>\n",
       "      <td>62.974</td>\n",
       "      <td>96.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC() _ Train Details</th>\n",
       "      <td>97.212</td>\n",
       "      <td>97.002</td>\n",
       "      <td>95.897</td>\n",
       "      <td>98.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC() _ Test Details</th>\n",
       "      <td>90.15</td>\n",
       "      <td>89.64</td>\n",
       "      <td>90.045</td>\n",
       "      <td>89.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier() _ Train Details</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier() _ Test Details</th>\n",
       "      <td>85.439</td>\n",
       "      <td>85.153</td>\n",
       "      <td>82.979</td>\n",
       "      <td>87.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier() _ Train Details</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier() _ Test Details</th>\n",
       "      <td>91.863</td>\n",
       "      <td>91.284</td>\n",
       "      <td>93.427</td>\n",
       "      <td>89.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB() _ Train Details</th>\n",
       "      <td>96.212</td>\n",
       "      <td>95.875</td>\n",
       "      <td>95.95</td>\n",
       "      <td>95.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB() _ Test Details</th>\n",
       "      <td>89.507</td>\n",
       "      <td>89.087</td>\n",
       "      <td>88.496</td>\n",
       "      <td>89.686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Accuracy F1_score Precision  Recall\n",
       "LogisticRegression() _ Train Details        100.0    100.0     100.0   100.0\n",
       "LogisticRegression() _ Test Details        91.863   91.593    90.393  92.825\n",
       "KNeighborsClassifier() _ Train Details     74.196   77.592    64.566  97.201\n",
       "KNeighborsClassifier() _ Test Details      71.306   76.325    62.974  96.861\n",
       "SVC() _ Train Details                      97.212   97.002    95.897  98.134\n",
       "SVC() _ Test Details                        90.15    89.64    90.045  89.238\n",
       "DecisionTreeClassifier() _ Train Details    100.0    100.0     100.0   100.0\n",
       "DecisionTreeClassifier() _ Test Details    85.439   85.153    82.979  87.444\n",
       "RandomForestClassifier() _ Train Details    100.0    100.0     100.0   100.0\n",
       "RandomForestClassifier() _ Test Details    91.863   91.284    93.427  89.238\n",
       "MultinomialNB() _ Train Details            96.212   95.875     95.95  95.801\n",
       "MultinomialNB() _ Test Details             89.507   89.087    88.496  89.686"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_models = [LogisticRegression() , KNeighborsClassifier() , SVC(kernel='rbf'), \n",
    "                  DecisionTreeClassifier() ,RandomForestClassifier(), MultinomialNB()]\n",
    "classification_report = pd.DataFrame(columns=['Accuracy','F1_score','Precision','Recall'])\n",
    "\n",
    "for model in list_of_models :\n",
    "    model = model.fit(X_train , y_train)\n",
    "    for i in range(2) :\n",
    "        if i == 0 :\n",
    "            to_pred = X_train\n",
    "            pred = y_train\n",
    "            title = 'Train'\n",
    "            \n",
    "        else :\n",
    "            to_pred = X_test\n",
    "            pred = y_test\n",
    "            title = 'Test'\n",
    "        y_pred = model.predict(to_pred)\n",
    "        acc = round(accuracy_score(pred , y_pred)*100, 3)\n",
    "        f1 = round(f1_score(pred , y_pred)*100, 3)\n",
    "        prec = round(precision_score(pred , y_pred)*100, 3)\n",
    "        recall = round(recall_score(pred , y_pred)*100, 3)\n",
    "        d = pd.DataFrame(data=np.array([acc,f1,prec,recall]).reshape(1,4) \n",
    "                     , columns=['Accuracy' , 'F1_score' , 'Precision' , 'Recall'])  \n",
    "        classification_report = pd.concat([classification_report , d])\n",
    "        classification_report.rename( index= { 0 :'{} _ {} Details'.format(model , title) } ,inplace=True )\n",
    "pd.options.display.max_rows = 15\n",
    "classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f21424c1",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67057da7",
   "metadata": {},
   "source": [
    "### Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0550c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Train Accuracy :  0.974\n",
      "Best Cross Validation Accuracy :  0.909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score\n",
    "logitic_regression = LogisticRegression()\n",
    "     \n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01],\n",
    "    'solver' : ['liblinear']}\n",
    "grid_search_lr = GridSearchCV(logitic_regression,param_grid = param_grid , cv=skf,return_train_score=True)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "model_lr = grid_search_lr.best_estimator_\n",
    "model_lr.fit(X_train,y_train)\n",
    "y_hat_lr = model_lr.predict(X_train)\n",
    "\n",
    "print('Best Parameters: ', grid_search_lr.best_params_)\n",
    "print('Best Train Accuracy : ', round(accuracy_score(y_hat_lr,y_train), 3))\n",
    "print('Best Cross Validation Accuracy : ', round(grid_search_lr.best_score_, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3feaa11",
   "metadata": {},
   "source": [
    "### Prediction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e67f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Train Set Accuracy Score:  0.981\n",
      "Hold-out Test Set Accuracy Score:  0.921\n",
      "Hold-out Train Set Precision Score:  0.981\n",
      "Hold-out Test Set Precision Score:  0.916\n",
      "Hold-out Train Set Recall Score:  0.977\n",
      "Hold-out Test Set Recall Score:  0.912\n"
     ]
    }
   ],
   "source": [
    "# Fit best estimator\n",
    "clf_lr = grid_search_lr.best_estimator_ \n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict training and testing set\n",
    "y_pred_lr_train = clf_lr.predict(X_train)\n",
    "y_pred_lr_test = clf_lr.predict(X_test)\n",
    "\n",
    "# Prediction score\n",
    "print('Hold-out Train Set Accuracy Score: ', round(accuracy_score(y_train, y_pred_lr_train), 3))\n",
    "print('Hold-out Test Set Accuracy Score: ', round(accuracy_score(y_test, y_pred_lr_test), 3))\n",
    "print('Hold-out Train Set Precision Score: ', round(precision_score(y_train, y_pred_lr_train), 3))\n",
    "print('Hold-out Test Set Precision Score: ', round(precision_score(y_test, y_pred_lr_test), 3))\n",
    "print('Hold-out Train Set Recall Score: ', round(recall_score(y_train, y_pred_lr_train), 3))\n",
    "print('Hold-out Test Set Recall Score: ', round(recall_score(y_test, y_pred_lr_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61be78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_lr = clf_lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b653c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score\n",
    "\n",
    "fpr_lr, tpr_lr, auc_thresholds_lr = roc_curve(y_test, y_scores_lr)\n",
    "optimal_idx_lr = np.argmax(tpr_lr - fpr_lr)\n",
    "optimal_idx_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c00ed4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4753123530282561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold_lr = auc_thresholds_lr[30]\n",
    "optimal_threshold_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "626b480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4753123530282561 is our optimized auc threshold \n",
      " 0.9398148148148148 is the recall score (TP) at there \n",
      " 0.07569721115537849 is the false positive rate at there\n"
     ]
    }
   ],
   "source": [
    "print(auc_thresholds_lr[30], 'is our optimized auc threshold \\n', \n",
    "      tpr_lr[30], 'is the recall score (TP) at there \\n',\n",
    "      fpr_lr[30], 'is the false positive rate at there') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e9cbe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Train Set Accuracy Score:  0.981\n",
      "Hold-out Test Set Accuracy Score:  0.931\n",
      "Hold-out Train Set Precision Score:  0.976\n",
      "Hold-out Test Set Precision Score:  0.914\n",
      "Hold-out Train Set Recall Score:  0.983\n",
      "Hold-out Test Set Recall Score:  0.94\n",
      "Hold-out Train Set F1 Score:  0.979\n",
      "Hold-out Test Set F1 Score:  0.927\n"
     ]
    }
   ],
   "source": [
    "y_scores_train_lr = clf_lr.predict_proba(X_train)[:, 1]\n",
    "y_scores_test_lr = clf_lr.predict_proba(X_test)[:, 1]\n",
    "new_pred_train_lr = (y_scores_train_lr   >= optimal_threshold_lr).astype(int)\n",
    "new_pred_test_lr = (y_scores_test_lr  >= optimal_threshold_lr).astype(int)\n",
    "# Prediction score\n",
    "print('Hold-out Train Set Accuracy Score: ', round(accuracy_score(y_train,new_pred_train_lr), 3))\n",
    "print('Hold-out Test Set Accuracy Score: ', round(accuracy_score(y_test, new_pred_test_lr), 3))\n",
    "print('Hold-out Train Set Precision Score: ', round(precision_score(y_train,new_pred_train_lr), 3))\n",
    "print('Hold-out Test Set Precision Score: ', round(precision_score(y_test, new_pred_test_lr), 3))\n",
    "print('Hold-out Train Set Recall Score: ', round(recall_score(y_train, new_pred_train_lr), 3))\n",
    "print('Hold-out Test Set Recall Score: ', round(recall_score(y_test, new_pred_test_lr), 3))\n",
    "print('Hold-out Train Set F1 Score: ', round(f1_score(y_train, new_pred_train_lr), 3))\n",
    "print('Hold-out Test Set F1 Score: ', round(f1_score(y_test, new_pred_test_lr), 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2007f511",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "778e1e65",
   "metadata": {},
   "source": [
    "### Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5029a8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m clf_rf \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) \n\u001b[1;32m      9\u001b[0m grid_search_rf \u001b[39m=\u001b[39m GridSearchCV(clf_rf, grid_rf, cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m grid_search_rf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     11\u001b[0m model_rf \u001b[39m=\u001b[39m grid_search_rf\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m     12\u001b[0m model_rf\u001b[39m.\u001b[39mfit(X_train,y_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GridSearchCV for Random Forest\n",
    "\n",
    "grid_rf = {'n_estimators': [10, 30, 50],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10, 15]}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "clf_rf = RandomForestClassifier(random_state=42) \n",
    "grid_search_rf = GridSearchCV(clf_rf, grid_rf, cv = 5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "model_rf = grid_search_rf.best_estimator_\n",
    "model_rf.fit(X_train,y_train)\n",
    "y_hat_rf = model_rf.predict(X_train)\n",
    "\n",
    "print('Best Parameters: ', grid_search_rf.best_params_)\n",
    "print('Best Train Accuracy : ', round(accuracy_score(y_hat_rf,y_train), 3))\n",
    "print('Best Cross Validation Accuracy : ', round(grid_search_rf.best_score_, 3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8396915",
   "metadata": {},
   "source": [
    "### Prediction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4e6ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Train Set Accuracy Score:  0.988\n",
      "Hold-out Test Set Accuracy Score:  0.916\n",
      "Hold-out Train Set Precision Score:  0.975\n",
      "Hold-out Test Set Precision Score:  0.897\n",
      "Hold-out Train Set Recall Score:  1.0\n",
      "Hold-out Test Set Recall Score:  0.91\n"
     ]
    }
   ],
   "source": [
    "# # Fit best estimator\n",
    "clf_rfb = grid_search_rf.best_estimator_ \n",
    "clf_rfb.fit(X_train, y_train)\n",
    "# Predict training and testing set\n",
    "y_pred_rfb_train = clf_rfb.predict(X_train)\n",
    "y_pred_rfb_test = clf_rfb.predict(X_test)\n",
    "\n",
    "# Prediction score\n",
    "print('Hold-out Train Set Accuracy Score: ', round(accuracy_score(y_train, y_pred_rfb_train), 3))\n",
    "print('Hold-out Test Set Accuracy Score: ', round(accuracy_score(y_test, y_pred_rfb_test), 3))\n",
    "print('Hold-out Train Set Precision Score: ', round(precision_score(y_train, y_pred_rfb_train), 3))\n",
    "print('Hold-out Test Set Precision Score: ', round(precision_score(y_test, y_pred_rfb_test), 3))\n",
    "print('Hold-out Train Set Recall Score: ', round(recall_score(y_train, y_pred_rfb_train), 3))\n",
    "print('Hold-out Test Set Recall Score: ', round(recall_score(y_test, y_pred_rfb_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7af4a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf_rfb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "571ffa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score\n",
    "\n",
    "fpr, tpr, auc_thresholds = roc_curve(y_test, y_scores)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f9f6b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4929287677032131"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold = auc_thresholds[34]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4764c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4929287677032131 is our optimized auc threshold \n",
      " 0.9212962962962963 is the recall score (TP) at there \n",
      " 0.035856573705179286 is the false positive rate at there\n"
     ]
    }
   ],
   "source": [
    "print(auc_thresholds[34], 'is our optimized auc threshold \\n', \n",
    "      tpr[34], 'is the recall score (TP) at there \\n',\n",
    "      fpr[34], 'is the false positive rate at there') \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "282d0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Train Set Accuracy Score:  0.987\n",
      "Hold-out Test Set Accuracy Score:  0.944\n",
      "Hold-out Train Set Precision Score:  0.976\n",
      "Hold-out Test Set Precision Score:  0.957\n",
      "Hold-out Train Set Recall Score:  0.997\n",
      "Hold-out Test Set Recall Score:  0.921\n",
      "Hold-out Train Set f1 Score:  0.986\n",
      "Hold-out Test Set f1 Score:  0.939\n"
     ]
    }
   ],
   "source": [
    "y_scores_train = clf_rfb.predict_proba(X_train)[:, 1]\n",
    "y_scores_test = clf_rfb.predict_proba(X_test)[:, 1]\n",
    "new_pred_train = (y_scores_train   >= optimal_threshold).astype(int)\n",
    "new_pred_test = (y_scores_test  >= optimal_threshold).astype(int)\n",
    "# Prediction score\n",
    "print('Hold-out Train Set Accuracy Score: ', round(accuracy_score(y_train,new_pred_train), 3))\n",
    "print('Hold-out Test Set Accuracy Score: ', round(accuracy_score(y_test, new_pred_test), 3))\n",
    "print('Hold-out Train Set Precision Score: ', round(precision_score(y_train,new_pred_train), 3))\n",
    "print('Hold-out Test Set Precision Score: ', round(precision_score(y_test, new_pred_test), 3))\n",
    "print('Hold-out Train Set Recall Score: ', round(recall_score(y_train, new_pred_train), 3))\n",
    "print('Hold-out Test Set Recall Score: ', round(recall_score(y_test, new_pred_test), 3))\n",
    "print('Hold-out Train Set f1 Score: ', round(f1_score(y_train, new_pred_train), 3))\n",
    "print('Hold-out Test Set f1 Score: ', round(f1_score(y_test, new_pred_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b7a4d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m nb_model \u001b[39m=\u001b[39m MultinomialNB(   )\n\u001b[1;32m      5\u001b[0m \u001b[39m# fit the dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m nb_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      7\u001b[0m nb_predict \u001b[39m=\u001b[39m nb_model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "# set the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# fit the dataset\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predict = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8e2b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  96.6 %\n",
      "Precision  63.7 %\n",
      "Recall  76.2 %\n",
      "f1_score  69.4 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "print(\"Accuracy  {:.3} %\".format(accuracy_score(y_test, nb_predict)*100))\n",
    "print(\"Precision  {:.3} %\".format(precision_score(y_test, nb_predict)*100))\n",
    "print(\"Recall  {:.3} %\".format(recall_score(y_test, nb_predict)*100))\n",
    "print(\"f1_score  {:.3} %\".format(f1_score(y_test, nb_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99e6517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# fit data using SVC\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfe80acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict output of the test data set\n",
    "predicted = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ac2e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  96.0 %\n",
      "Precision  1e+02 %\n",
      "Recall  19.3 %\n",
      "f1_score  32.3 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "print(\"Accuracy  {:.3} %\".format(accuracy_score(y_test, predicted)*100))\n",
    "print(\"Precision  {:.3} %\".format(precision_score(y_test, predicted)*100))\n",
    "print(\"Recall  {:.3} %\".format(recall_score(y_test, predicted)*100))\n",
    "print(\"f1_score  {:.3} %\".format(f1_score(y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b38bf42-6ef5-4ce6-8376-71febaebc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T\n",
    "    return indicator_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a97bb594-84f7-4b2e-92c7-ac85bcc8aeba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/9py3tkzj64s8p_nnkstb8kz40000gn/T/ipykernel_65772/3282851936.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ham_split = eda_ham['text'].str.replace(r'/<[^>]*>/g', ' ').str.split()\n",
      "/var/folders/83/9py3tkzj64s8p_nnkstb8kz40000gn/T/ipykernel_65772/3282851936.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  spam_split = eda_spam['text'].str.replace(r'/<[^>]*>/g', ' ').str.split()\n"
     ]
    }
   ],
   "source": [
    "eda_ham = df.loc[df['fraudulent']==0]\n",
    "eda_spam = df.loc[df['fraudulent']==1]\n",
    "\n",
    "num_ham, num_spam = {}, {}\n",
    "\n",
    "ham_split = eda_ham['text'].str.replace(r'/<[^>]*>/g', ' ').str.split()\n",
    "spam_split = eda_spam['text'].str.replace(r'/<[^>]*>/g', ' ').str.split()\n",
    "\n",
    "#put word frequencies in dictionaries\n",
    "for i in ham_split:\n",
    "    for j in i:\n",
    "        if num_ham.get(j) is None:\n",
    "            num_ham[j] = 1\n",
    "        num_ham[j] = num_ham[j] + 1\n",
    "for i in spam_split:\n",
    "    for j in i:\n",
    "        if num_spam.get(j) is None:\n",
    "            num_spam[j] = 1\n",
    "        num_spam[j] = num_spam[j] + 1\n",
    "        \n",
    "#sorted_ham = sorted(num_ham, key = num_ham.get, reverse = True)\n",
    "sorted_spam = sorted(num_spam, key = num_spam.get, reverse = True)\n",
    "len(sorted_spam) #95402 pairs in the dictionary\n",
    "\n",
    "feature = []\n",
    "for i in np.arange(1200):\n",
    "    feature.append(sorted_spam[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4b112c8-50c6-4e1e-bdce-affdf40090f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "77e99a44-7966-46a4-a96f-455c8ec48bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9603467561521253\n",
      "Precision score: 0.2690531177829099\n",
      "Recall score: 0.7540453074433657\n",
      "F1 score: 0.39659574468085107\n"
     ]
    }
   ],
   "source": [
    "arr_feature = ['work', 'experience', 'time', 'skills', 'amp', 'us', 'full', 'company', 'team', 'service', 'management', \n",
    "               'business', 'customer', 'ability', 'services', 'position', 'engineering', 'level', 'high', 'data', 'project',\n",
    "               'entry', 'industry', 'required', 'environment', 'new', 'must', 'solutions', 'years', 'job', 'support', 'development', \n",
    "               'products', 'knowledge', 'working', 'systems', 'looking', 'information', 'provide', 'office', 'within', 'benefits',\n",
    "               'candidates', 'people', 'product', 'requirements', 'sales', 'including', 'equipment', 'process', 'oil', 'communication', \n",
    "               'strong', 'technology', 'design', 'degree', 'customers', 'able', 'per', 'home', 'manager', 'training', 'quality', \n",
    "               'technical', 'false', 'good', 'professional', '1', 'opportunity', 'computer', 'school', '000', 'apply', 'develop',\n",
    "               'well', 'responsibilities', 'administrative', 'ensure', 'excellent', 'part', 'help', '2', 'system', 'field', 'employees',\n",
    "               'duties', 'perform', 'equivalent', 'get', 'please', 'client', 'world', 'responsible', 'gas', 'needed', 'test', 'operations', \n",
    "               'maintain', 'software', 'projects', 'production', 'preferred', 'ca', 'maintenance', 'related', 'positions', 'clients', \n",
    "               'offer', 'global', 'aker', 'contract', 'food', 'program', 'based', '3', 'start', 'bonus', 'paid']\n",
    "\n",
    "train_X = words_in_texts(arr_feature, df['text'])\n",
    "train_Y = np.array(df['fraudulent'])\n",
    "model_eda = LogisticRegression()\n",
    "model_eda.fit(train_X, train_Y)\n",
    "\n",
    "pred = model_eda.predict(train_X)\n",
    "new_training_accuracy = model_eda.score(train_X, train_Y)\n",
    "\n",
    "# print(\"Accuracy: \", new_training_accuracy)\n",
    "print('Accuracy score:' , accuracy_score(pred, train_Y))\n",
    "print('Precision score:', precision_score(pred, train_Y))\n",
    "print ('Recall score:', recall_score(pred, train_Y))\n",
    "print ('F1 score:', f1_score(pred, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2500075-2597-4ede-b3f7-31abbcdaa72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 words\n",
      "Accuracy score: 0.9513982102908277\n",
      "Precision score: 0.018475750577367205\n",
      "Recall score: 0.45714285714285713\n",
      "F1 score: 0.03551609322974473\n",
      "100 words\n",
      "Accuracy score: 0.9591163310961969\n",
      "Precision score: 0.23672055427251731\n",
      "Recall score: 0.7454545454545455\n",
      "F1 score: 0.35933391761612615\n",
      "200 words\n",
      "Accuracy score: 0.9665548098434005\n",
      "Precision score: 0.41454965357967666\n",
      "Recall score: 0.7977777777777778\n",
      "F1 score: 0.5455927051671733\n",
      "300 words\n",
      "Accuracy score: 0.9741610738255033\n",
      "Precision score: 0.5623556581986143\n",
      "Recall score: 0.8543859649122807\n",
      "F1 score: 0.6782729805013928\n",
      "400 words\n",
      "Accuracy score: 0.9787472035794184\n",
      "Precision score: 0.6593533487297921\n",
      "Recall score: 0.8704268292682927\n",
      "F1 score: 0.7503285151116951\n",
      "500 words\n",
      "Accuracy score: 0.9824384787472036\n",
      "Precision score: 0.7193995381062356\n",
      "Recall score: 0.8976945244956772\n",
      "F1 score: 0.7987179487179488\n",
      "600 words\n",
      "Accuracy score: 0.9858501118568233\n",
      "Precision score: 0.7609699769053118\n",
      "Recall score: 0.9347517730496454\n",
      "F1 score: 0.8389560789306174\n",
      "700 words\n",
      "Accuracy score: 0.987751677852349\n",
      "Precision score: 0.7909930715935335\n",
      "Recall score: 0.9474412171507607\n",
      "F1 score: 0.8621774701069856\n",
      "800 words\n",
      "Accuracy score: 0.9896532438478747\n",
      "Precision score: 0.8198614318706697\n",
      "Recall score: 0.9607577807848444\n",
      "F1 score: 0.8847352024922117\n",
      "900 words\n",
      "Accuracy score: 0.9916107382550335\n",
      "Precision score: 0.8498845265588915\n",
      "Recall score: 0.9735449735449735\n",
      "F1 score: 0.907521578298397\n",
      "1000 words\n",
      "Accuracy score: 0.9937360178970918\n",
      "Precision score: 0.8833718244803695\n",
      "Recall score: 0.9858247422680413\n",
      "F1 score: 0.9317904993909866\n",
      "1100 words\n",
      "Accuracy score: 0.9947986577181208\n",
      "Precision score: 0.9064665127020786\n",
      "Recall score: 0.9849435382685069\n",
      "F1 score: 0.9440769693325316\n",
      "1200 words\n",
      "Accuracy score: 0.9961968680089486\n",
      "Precision score: 0.9295612009237876\n",
      "Recall score: 0.9913793103448276\n",
      "F1 score: 0.9594755661501787\n"
     ]
    }
   ],
   "source": [
    "num_words = [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
    "\n",
    "accuracy_score_lst = []\n",
    "precision_score_lst = []\n",
    "recall_score_lst = []\n",
    "f1_score_lst = []\n",
    "\n",
    "for num in num_words:\n",
    "    arr_feature = feature[:num]\n",
    "    \n",
    "    train_X = words_in_texts(arr_feature, train_X)\n",
    "    train_Y = np.array(df['fraudulent'])\n",
    "    \n",
    "    model_eda = LogisticRegression(max_iter=10000)\n",
    "    model_eda.fit(train_X, train_Y)\n",
    "\n",
    "    pred = model_eda.predict(train_X)\n",
    "    new_training_accuracy = model_eda.score(train_X, train_Y)\n",
    "\n",
    "    # print(\"Accuracy: \", new_training_accuracy)\n",
    "    print(num, 'words')\n",
    "    print('Accuracy score:' , accuracy_score(pred, train_Y))\n",
    "    print('Precision score:', precision_score(pred, train_Y))\n",
    "    print ('Recall score:', recall_score(pred, train_Y))\n",
    "    print ('F1 score:', f1_score(pred, train_Y))\n",
    "    \n",
    "    accuracy_score_lst.append(accuracy_score(pred, train_Y))\n",
    "    precision_score_lst.append(precision_score(pred, train_Y))\n",
    "    recall_score_lst.append(recall_score(pred, train_Y))\n",
    "    f1_score_lst.append(f1_score(pred, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e42a73-b42b-4ce3-bdfb-e07049884f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d6c1318-9757-43bc-b50f-181a9ab7de6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.951398</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.035516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.959116</td>\n",
       "      <td>0.236721</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.359334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.966555</td>\n",
       "      <td>0.414550</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.545593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.974161</td>\n",
       "      <td>0.562356</td>\n",
       "      <td>0.854386</td>\n",
       "      <td>0.678273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.978747</td>\n",
       "      <td>0.659353</td>\n",
       "      <td>0.870427</td>\n",
       "      <td>0.750329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.982438</td>\n",
       "      <td>0.719400</td>\n",
       "      <td>0.897695</td>\n",
       "      <td>0.798718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.985850</td>\n",
       "      <td>0.760970</td>\n",
       "      <td>0.934752</td>\n",
       "      <td>0.838956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.987752</td>\n",
       "      <td>0.790993</td>\n",
       "      <td>0.947441</td>\n",
       "      <td>0.862177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.989653</td>\n",
       "      <td>0.819861</td>\n",
       "      <td>0.960758</td>\n",
       "      <td>0.884735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.991611</td>\n",
       "      <td>0.849885</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.907522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.993736</td>\n",
       "      <td>0.883372</td>\n",
       "      <td>0.985825</td>\n",
       "      <td>0.931790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.994799</td>\n",
       "      <td>0.906467</td>\n",
       "      <td>0.984944</td>\n",
       "      <td>0.944077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0.996197</td>\n",
       "      <td>0.929561</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.959476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision    Recall        F1\n",
       "50    0.951398   0.018476  0.457143  0.035516\n",
       "100   0.959116   0.236721  0.745455  0.359334\n",
       "200   0.966555   0.414550  0.797778  0.545593\n",
       "300   0.974161   0.562356  0.854386  0.678273\n",
       "400   0.978747   0.659353  0.870427  0.750329\n",
       "500   0.982438   0.719400  0.897695  0.798718\n",
       "600   0.985850   0.760970  0.934752  0.838956\n",
       "700   0.987752   0.790993  0.947441  0.862177\n",
       "800   0.989653   0.819861  0.960758  0.884735\n",
       "900   0.991611   0.849885  0.973545  0.907522\n",
       "1000  0.993736   0.883372  0.985825  0.931790\n",
       "1100  0.994799   0.906467  0.984944  0.944077\n",
       "1200  0.996197   0.929561  0.991379  0.959476"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Accuracy':accuracy_score_lst,\n",
    "              'Precision':precision_score_lst,\n",
    "              'Recall':recall_score_lst,\n",
    "              'F1':f1_score_lst,\n",
    "             }, index=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b65ae5e-250b-473d-a25a-817ebf39c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 words\n",
      "Accuracy score: 0.9496644295302014\n",
      "Precision score: 0.017937219730941704\n",
      "Recall score: 0.4\n",
      "F1 score: 0.034334763948497854\n",
      "100 words\n",
      "Accuracy score: 0.9579418344519016\n",
      "Precision score: 0.242152466367713\n",
      "Recall score: 0.7397260273972602\n",
      "F1 score: 0.36486486486486486\n",
      "200 words\n",
      "Accuracy score: 0.9635346756152126\n",
      "Precision score: 0.3901345291479821\n",
      "Recall score: 0.7631578947368421\n",
      "F1 score: 0.5163204747774481\n",
      "300 words\n",
      "Accuracy score: 0.9691275167785235\n",
      "Precision score: 0.5112107623318386\n",
      "Recall score: 0.7972027972027972\n",
      "F1 score: 0.6229508196721312\n",
      "400 words\n",
      "Accuracy score: 0.9713646532438479\n",
      "Precision score: 0.547085201793722\n",
      "Recall score: 0.8187919463087249\n",
      "F1 score: 0.6559139784946236\n",
      "500 words\n",
      "Accuracy score: 0.9727069351230425\n",
      "Precision score: 0.6457399103139013\n",
      "Recall score: 0.7700534759358288\n",
      "F1 score: 0.7024390243902439\n",
      "600 words\n",
      "Accuracy score: 0.9751677852348993\n",
      "Precision score: 0.6771300448430493\n",
      "Recall score: 0.7947368421052632\n",
      "F1 score: 0.7312348668280871\n",
      "700 words\n",
      "Accuracy score: 0.9749440715883669\n",
      "Precision score: 0.6681614349775785\n",
      "Recall score: 0.7967914438502673\n",
      "F1 score: 0.726829268292683\n",
      "800 words\n",
      "Accuracy score: 0.9758389261744966\n",
      "Precision score: 0.6771300448430493\n",
      "Recall score: 0.8074866310160428\n",
      "F1 score: 0.7365853658536585\n",
      "900 words\n",
      "Accuracy score: 0.9787472035794184\n",
      "Precision score: 0.7130044843049327\n",
      "Recall score: 0.8368421052631579\n",
      "F1 score: 0.7699757869249394\n",
      "1000 words\n",
      "Accuracy score: 0.978076062639821\n",
      "Precision score: 0.7130044843049327\n",
      "Recall score: 0.8238341968911918\n",
      "F1 score: 0.764423076923077\n",
      "1100 words\n",
      "Accuracy score: 0.9787472035794184\n",
      "Precision score: 0.726457399103139\n",
      "Recall score: 0.826530612244898\n",
      "F1 score: 0.7732696897374702\n",
      "1200 words\n",
      "Accuracy score: 0.9782997762863535\n",
      "Precision score: 0.7174887892376681\n",
      "Recall score: 0.8247422680412371\n",
      "F1 score: 0.7673860911270982\n"
     ]
    }
   ],
   "source": [
    "num_words = [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
    "\n",
    "accuracy_score_lst = []\n",
    "precision_score_lst = []\n",
    "recall_score_lst = []\n",
    "f1_score_lst = []\n",
    "\n",
    "for num in num_words:\n",
    "    arr_feature = feature[:num]\n",
    "    \n",
    "    train_X = words_in_texts(arr_feature, X_train)\n",
    "    train_Y = np.array(y_train)\n",
    "    \n",
    "    test_x = words_in_texts(arr_feature, X_test)\n",
    "    test_y = np.array(y_test)\n",
    "    \n",
    "    model_eda = LogisticRegression(max_iter=10000)\n",
    "    model_eda.fit(train_X, train_Y)\n",
    "\n",
    "    pred = model_eda.predict(test_x)\n",
    "    new_training_accuracy = model_eda.score(train_X, train_Y)\n",
    "\n",
    "    # print(\"Accuracy: \", new_training_accuracy)\n",
    "    print(num, 'words')\n",
    "    print('Accuracy score:' , accuracy_score(pred, y_test))\n",
    "    print('Precision score:', precision_score(pred, y_test))\n",
    "    print ('Recall score:', recall_score(pred, y_test))\n",
    "    print ('F1 score:', f1_score(pred, y_test))\n",
    "    \n",
    "    accuracy_score_lst.append(accuracy_score(pred, y_test))\n",
    "    precision_score_lst.append(precision_score(pred, y_test))\n",
    "    recall_score_lst.append(recall_score(pred, y_test))\n",
    "    f1_score_lst.append(f1_score(pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "119554a6-87a4-4dd9-b4cf-60a0450f15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.034335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.957942</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.364865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.963535</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.516320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.969128</td>\n",
       "      <td>0.511211</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.971365</td>\n",
       "      <td>0.547085</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.655914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.972707</td>\n",
       "      <td>0.645740</td>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.702439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.975168</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.731235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.668161</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.726829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.975839</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.736585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.978747</td>\n",
       "      <td>0.713004</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.769976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.713004</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.764423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.978747</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.773270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.717489</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.767386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision    Recall        F1\n",
       "50    0.949664   0.017937  0.400000  0.034335\n",
       "100   0.957942   0.242152  0.739726  0.364865\n",
       "200   0.963535   0.390135  0.763158  0.516320\n",
       "300   0.969128   0.511211  0.797203  0.622951\n",
       "400   0.971365   0.547085  0.818792  0.655914\n",
       "500   0.972707   0.645740  0.770053  0.702439\n",
       "600   0.975168   0.677130  0.794737  0.731235\n",
       "700   0.974944   0.668161  0.796791  0.726829\n",
       "800   0.975839   0.677130  0.807487  0.736585\n",
       "900   0.978747   0.713004  0.836842  0.769976\n",
       "1000  0.978076   0.713004  0.823834  0.764423\n",
       "1100  0.978747   0.726457  0.826531  0.773270\n",
       "1200  0.978300   0.717489  0.824742  0.767386"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Accuracy':accuracy_score_lst,\n",
    "              'Precision':precision_score_lst,\n",
    "              'Recall':recall_score_lst,\n",
    "              'F1':f1_score_lst,\n",
    "             }, index=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "076ab38f-6898-4144-95c4-d15e020f3d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food52 created groundbreaking award winning co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90 seconds worlds cloud video production servi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valor services provides workforce solutions me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passion improving quality life geography heart...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotsource solutions llc global human capital ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>job overview apex environmental consulting fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>founded 2009 fonpit ag rose international web ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airenvy mission provide lucrative yet hassle f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>solutions3 woman owned small business whose fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>novitex enterprise solutions formerly pitney b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>position developerjob location united states n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>want build 21st century financial service conv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>novitex enterprise solutions formerly pitney b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>growing event production company providing sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adthena uk leading competitive intelligence se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jungle ventures leading singapore based entrep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>honeybook imagining events industry building p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>established principles full time education eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kettle independent digital agency based new yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>provide full time permanent positions many med...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>intellibright created leverage enterprise leve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>frustrated status quo like imagine whats possi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  fraudulent\n",
       "0   food52 created groundbreaking award winning co...           0\n",
       "1   90 seconds worlds cloud video production servi...           0\n",
       "2   valor services provides workforce solutions me...           0\n",
       "3   passion improving quality life geography heart...           0\n",
       "4   spotsource solutions llc global human capital ...           0\n",
       "5   job overview apex environmental consulting fir...           0\n",
       "6   founded 2009 fonpit ag rose international web ...           0\n",
       "7   airenvy mission provide lucrative yet hassle f...           0\n",
       "8   solutions3 woman owned small business whose fo...           0\n",
       "9   novitex enterprise solutions formerly pitney b...           0\n",
       "10  position developerjob location united states n...           0\n",
       "11  want build 21st century financial service conv...           0\n",
       "12  novitex enterprise solutions formerly pitney b...           0\n",
       "13  growing event production company providing sta...           0\n",
       "14  adthena uk leading competitive intelligence se...           0\n",
       "15  jungle ventures leading singapore based entrep...           0\n",
       "16  honeybook imagining events industry building p...           0\n",
       "17  established principles full time education eve...           0\n",
       "18  kettle independent digital agency based new yo...           0\n",
       "19  provide full time permanent positions many med...           0\n",
       "20  intellibright created leverage enterprise leve...           0\n",
       "21  frustrated status quo like imagine whats possi...           0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
