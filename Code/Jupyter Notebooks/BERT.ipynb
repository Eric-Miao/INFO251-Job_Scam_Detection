{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mnBI0P-OC679"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eric/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,recall_score,precision_score,f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "\n",
        "from keras.metrics import AUC,Recall,Precision,BinaryAccuracy\n",
        "import keras.backend as K\n",
        "from keras.layers import Hashing\n",
        "from keras.utils import pad_sequences\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPMtLUh9DOQG",
        "outputId": "9e1ab01e-d0cb-429e-de4b-e9a6002b35a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# changes directory from colab to gdrive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_path = '/content/drive/MyDrive/INFO251_Fake_Job_Detection/'\n",
        "os.chdir(base_path)\n",
        "baseline_csv = './Data/text.csv'  # data dictionary\n",
        "data = os.path.join(base_path, baseline_csv)\n",
        "dfRaw = pd.read_csv(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdxQzAqelki9"
      },
      "source": [
        "# Read in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wn_Yji4Az2wP"
      },
      "outputs": [],
      "source": [
        "dfRaw = pd.read_csv('../../Data/text.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Uj-QGW_lum_"
      },
      "source": [
        "## Train-test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kPD9WQIEOTi6"
      },
      "outputs": [],
      "source": [
        "labels=np.array(dfRaw.fraudulent.map({'t':1,'f':0}).to_list()).reshape((-1,1))\n",
        "X_train,X_test,y_train,y_test=train_test_split(dfRaw.text,labels,test_size=0.25,random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13410"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARtwuOjS9JtV"
      },
      "source": [
        "# Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj9sXlceMZYR"
      },
      "outputs": [],
      "source": [
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n96jOFDfmJLf"
      },
      "source": [
        "## Define my BERT Class for taining and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZCG28CX1xVl"
      },
      "outputs": [],
      "source": [
        "class MyBERT():\n",
        "  def __init__(self,bert_model_name='small_bert/bert_en_uncased_L-4_H-512_A-8'):\n",
        "    self.bert_model_name = bert_model_name\n",
        "    \n",
        "    self.tfhub_handle_encoder = map_name_to_handle[self.bert_model_name]\n",
        "    self.tfhub_handle_preprocess = map_model_to_preprocess[self.bert_model_name]\n",
        "\n",
        "    print(f'BERT model selected           : {self.tfhub_handle_encoder}')\n",
        "    print(f'Preprocess model auto-selected: {self.tfhub_handle_preprocess}')\n",
        "    self.bert_preprocess_model = hub.KerasLayer(self.tfhub_handle_preprocess, name='preprocessing')\n",
        "    self.bert_model = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "\n",
        "  def build_classifier_model(self,r_dropout=0.1):\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = self.bert_preprocess_model\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = self.bert_model\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(r_dropout)(net)\n",
        "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "    return tf.keras.Model(text_input, net)\n",
        "\n",
        "  def fit(self,X_train,y_train,class_wight=[1.0,1.0]):\n",
        "    def F1Score(y_true, y_pred): #taken from old keras source code\n",
        "      true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "      possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "      predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "      precision = true_positives / (predicted_positives + K.epsilon())\n",
        "      recall = true_positives / (possible_positives + K.epsilon())\n",
        "      f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "      return f1_val\n",
        "\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    metric = [AUC(),Recall(),Precision(),BinaryAccuracy(),F1Score]\n",
        "    epochs = 15\n",
        "    steps_per_epoch = len(X_train)\n",
        "    num_train_steps = steps_per_epoch * epochs\n",
        "    num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "    init_lr = 3e-5\n",
        "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                              num_train_steps=num_train_steps,\n",
        "                                              num_warmup_steps=num_warmup_steps,\n",
        "                                              optimizer_type='adamw')\n",
        "\n",
        "    self.classifier_model = self.build_classifier_model()\n",
        "    self.classifier_model.compile(optimizer=optimizer,\n",
        "                            loss=loss,\n",
        "                            metrics=metric)\n",
        "\n",
        "    print(f'Training model with {self.tfhub_handle_encoder}')\n",
        "    history = self.classifier_model.fit(x=X_train,y=y_train,\n",
        "                                  validation_split=0.2,\n",
        "                                  class_weight={0:class_wight[0],1:class_wight[1]},\n",
        "                                  epochs=epochs)\n",
        "    return history\n",
        "\n",
        "  def eval(self,X_test,y_test):\n",
        "    return self.classifier_model.evaluate(x=X_test,y=y_test)\n",
        "\n",
        "  def save(self,hyperparam):\n",
        "    saved_model_path = './Model/BERT_MODEL/{}_bert'.format('_'.join(hyperparam))\n",
        "    self.classifier_model.save(saved_model_path, include_optimizer=False)\n",
        "    print(f'model {saved_model_path} saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vebV6rbimUdT"
      },
      "source": [
        "## Get ready for hyper-parameter tunning and general training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sQ_c2xFenGz"
      },
      "outputs": [],
      "source": [
        "dfModelCompare = pd.DataFrame(\n",
        "    columns=['name','model','dropout_r','class_0','class_1','loss','auc','recall','precision','accu','f1']\n",
        "    )\n",
        "models = ['small_bert/bert_en_uncased_L-4_H-512_A-8',\n",
        "          'small_bert/bert_en_uncased_L-8_H-512_A-8',\n",
        "          'bert_en_uncased_L-12_H-768_A-12']\n",
        "dropout_r = [0.1,0.2,0.3,0.5,0.6]\n",
        "class_weight = [[1.0,1.0],[1.0,1.5],[1.0,2.0],[1.0,3.0],[1.0,5.0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RofXF9lKFygj"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "for m in models:\n",
        "  model = MyBERT(bert_model_name=m)\n",
        "  for r in dropout_r:\n",
        "    model.build_classifier_model(r)\n",
        "    for w in class_weight:\n",
        "      if cnt<8:\n",
        "        cnt += 1\n",
        "        continue\n",
        "      model.fit(X_train,y_train,w)\n",
        "      results = model.eval(X_test,y_test)\n",
        "      model.save([str(cnt),str(r),str(w[0]),str(w[1])])\n",
        "      cnt+=1\n",
        "      dfModelCompare.loc[len(dfModelCompare.index)] = [cnt,m,r]+w+results\n",
        "      # Record training results\n",
        "      dfModelCompare.to_csv('Model_Compare.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2O8TIm1Anc"
      },
      "source": [
        "# Read in the best model so far and do prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kCICy40lYgK"
      },
      "outputs": [],
      "source": [
        "def F1Score(y_true, y_pred): #taken from old keras source code\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "  return f1_val\n",
        "best_model = './Model/BERT_MODEL/7_0.2_1.0_2.0_bert'\n",
        "reloaded_model = tf.keras.saving.load_model(best_model,custom_objects={'F1Score':F1Score})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZuXRBQxmwQn",
        "outputId": "967cb516-8759-4429-c03f-b9069e755651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 395s 3s/step - loss: 0.1133 - auc: 0.9090 - recall: 0.8206 - precision: 0.9433 - binary_accuracy: 0.9886 - F1Score: 0.6935\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.11328911036252975,\n",
              " 0.909018874168396,\n",
              " 0.8206278085708618,\n",
              " 0.9432989954948425,\n",
              " 0.9885905981063843,\n",
              " 0.693500280380249]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metric = [AUC(),Recall(),Precision(),BinaryAccuracy(),F1Score]\n",
        "epochs = 15\n",
        "steps_per_epoch = len(X_train)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                      num_train_steps=num_train_steps,\n",
        "                      num_warmup_steps=num_warmup_steps,\n",
        "                      optimizer_type='adamw')\n",
        "\n",
        "reloaded_model.compile(optimizer=optimizer,\n",
        "            loss=loss,\n",
        "            metrics=metric)\n",
        "reloaded_model.evaluate(x=X_test,y=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISaLN5Kp1Hu2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
